{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TR_2021/18 - Technical report: Case crossover for cardiovascular hospitalizations and extreme events.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1q4ZYD6_Aw4a2PNAsrexExwo8gIBo_fjV",
      "authorship_tag": "ABX9TyPlnGDPtj9utkF4SMiDtBth"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC1woAU0fTl8"
      },
      "source": [
        "# **TR_2021/18 - Technical report: Case crossover for cardiovascular hospitalizations and extreme events**\n",
        "\n",
        "\n",
        "|Technical Report ID  |2021/18|\n",
        "|--|--|\n",
        "| Title |Case crossover for cardiovascular hospitalizations and extreme events|\n",
        "| Authors | Júlia De Lázari, Paula Dornhofer|\n",
        "| Creation Date| 2021-08|\n",
        "\n",
        "\n",
        "## Databases descriptions\n",
        "\n",
        "**inputs:** \n",
        "\n",
        "- hospitalizações_circulatorio.csv: Dataframe of hospitalizations due to cardiovascular diseases from 2014 to 2018.\n",
        "\n",
        "- EV_VCP.csv: Dataframe with the extreme events computed. Viracopos data was used for this.\n",
        "\n",
        "## Analysis\n",
        "\n",
        "This report presents an analysis of the the _incidence rate ratio_ for the [extreme climate events](https://github.com/climate-and-health-datasci-Unicamp/project-climatic-variations-cardiovascular-diseases/blob/main/notebooks/TR_2020_05_Extreme_climatic_events_for_Campinas.ipynb) using a case crossover design."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGmKFn1mfSce"
      },
      "source": [
        "##**Case crossover**\n",
        "\n",
        "In a case-crossover study design, each person serves as his own control. The period immediately before the adverse outcome (death or hospitalization) is then compared with a period when no adverse outcome occurred [Gordis].\n",
        "\n",
        "As the analyzed events are rare, we used a random number to generate the control for each patient to avoid bias. The number used was between 30 and 300. We considered a period of exposure of 5 days, i.e., we compared the exposure to extreme climatic events on the five days before the (case) with the exposure five days before the control.\n",
        "\n",
        "Then, we performed a conditional logistic regression to obtain estimates of odds ratios (OR) and theirs 95 \\% confidence interval. Because of the sampling strategy and the small initial risk (chance of a cardiovascular outcome in the city of Campinas), these ORs can be considered a reasonable estimate of the incidence rate ratio (IRR) [Davies].\n",
        "\n",
        "Besides the extreme event of interest, meteorological parameters of maximum temperature, average pressure, and maximum humidity were included in all the regressions. Minimum temperature and humidity were not included due to the high correlation with the maximum temperature and humidity.\n",
        "\n",
        "Because we used a random number to define the control, the results will be different each time. We used the mean value of 20 regressions to estimate the RR associated with each extreme event."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SqMzEwKESAC"
      },
      "source": [
        "##**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSB-qmB_2zYt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad7b1ff-6c79-425f-fc2b-8b86c764fb11"
      },
      "source": [
        "#import python libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import math\n",
        "import statistics as stat\n",
        "import scipy.stats as stats\n",
        "import datetime as dt\n",
        "import random\n",
        "\n",
        "#plots\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import rcParams\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as mticker\n",
        "\n",
        "#array \n",
        "from array import array\n",
        "from itertools import repeat\n",
        "\n",
        "#logistic regression\n",
        "import statsmodels.api as sm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#files\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQikBalDEUfw"
      },
      "source": [
        "##**Load data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz-avXtJQNiN"
      },
      "source": [
        "###**Climatic data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYTIPHCEEWE3"
      },
      "source": [
        "#-------------------------------------------------------------------#\n",
        "#                          Load Viracopos data                      #\n",
        "#-------------------------------------------------------------------#\n",
        "\n",
        "#Load humidity dataframe\n",
        "df_VCP = pd.read_csv('EV_VCP.csv')\n",
        "df_VCP = df_VCP.drop(columns = {'Unnamed: 0'})\n",
        "df_VCP['DATE'] = pd.to_datetime(df_VCP['DATE'])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXyJrym4CznZ",
        "outputId": "3509c652-7f94-4089-d010-a485a2dc1318"
      },
      "source": [
        "#-------------------------------------------------------------------#\n",
        "#                             Null rows                             #\n",
        "#-------------------------------------------------------------------#\n",
        "print(\"Percentage of null values VCP (2001-2018) \\n\")\n",
        "\n",
        "print(\"TMIN:\", round((len(df_VCP[df_VCP['TMIN'].isnull()]))/len(df_VCP)*100,2),\"%\")\n",
        "print(\"TMAX:\", round((len(df_VCP[df_VCP['TMAX'].isnull()]))/len(df_VCP)*100,2),\"%\")\n",
        "print(\"AVGPRESSURE:\", round((len(df_VCP[df_VCP['AVGPRESSURE'].isnull()]))/len(df_VCP)*100,2),\"%\")\n",
        "print(\"HMIN:\", round((len(df_VCP[df_VCP['HMIN'].isnull()]))/len(df_VCP)*100,2),\"%\")\n",
        "print(\"HMAX:\", round((len(df_VCP[df_VCP['HMAX'].isnull()]))/len(df_VCP)*100,2),\"%\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Number of null rows \\n\")\n",
        "\n",
        "print(\"TMIN:\", len(df_VCP[df_VCP['TMIN'].isnull()]))\n",
        "print(\"TMAX:\", len(df_VCP[df_VCP['TMAX'].isnull()]))\n",
        "print(\"AVGPRESSURE:\",len(df_VCP[df_VCP['AVGPRESSURE'].isnull()]))\n",
        "print(\"HMIN:\", len(df_VCP[df_VCP['HMIN'].isnull()]))\n",
        "print(\"HMAX:\", len(df_VCP[df_VCP['HMAX'].isnull()]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of null values VCP (2001-2018) \n",
            "\n",
            "TMIN: 0.18 %\n",
            "TMAX: 0.18 %\n",
            "AVGPRESSURE: 0.02 %\n",
            "HMIN: 0.05 %\n",
            "HMAX: 0.05 %\n",
            "\n",
            "\n",
            "Number of null rows \n",
            "\n",
            "TMIN: 12\n",
            "TMAX: 12\n",
            "AVGPRESSURE: 1\n",
            "HMIN: 3\n",
            "HMAX: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQhG2baSCzIB"
      },
      "source": [
        "#fill na with mean values\n",
        "df_VCP['HMIN'].fillna(df_VCP['HMIN'].mean(), inplace=True)\n",
        "df_VCP['HMAX'].fillna(df_VCP['HMAX'].mean(), inplace=True)\n",
        "df_VCP['TMIN'].fillna(df_VCP['TMIN'].mean(), inplace=True)\n",
        "df_VCP['TMAX'].fillna(df_VCP['TMAX'].mean(), inplace=True)\n",
        "df_VCP['AVGPRESSURE'].fillna(df_VCP['AVGPRESSURE'].mean(), inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK_CDc90QQMZ"
      },
      "source": [
        "###**Health data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i633SqEeaHm0"
      },
      "source": [
        "#-------------------------------------------------------------------#\n",
        "#                 Circulatory hospitalizations                      #\n",
        "#-------------------------------------------------------------------#\n",
        "\n",
        "df_hosp = pd.read_csv('hospitalizações_circulatório.csv')\n",
        "df_hosp = df_hosp.drop(columns = {'Unnamed: 0','Hora','Número Paciente','Descrição CID'}) #drop unneeded columns\n",
        "df_hosp = df_hosp.rename(columns = {'Data':'DATE','Idade': 'IDADE','Sexo': 'SEXO'}) #rename Data to DATE to merge dataframes\n",
        "df_hosp = df_hosp[(df_hosp.DATE !='2012-02-29')&(df_hosp.DATE !='2016-02-29')] #remove leap year dates (02-29)\n",
        "df_hosp = df_hosp.sort_values('DATE')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILvLOJiGR1Jd"
      },
      "source": [
        "##**Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgKdr5djR2wM"
      },
      "source": [
        "def case_crossover_random_exposed(df_health,df_climate,event,show):\n",
        "\n",
        "  #convert to datetime\n",
        "  df_health['DATE'] = pd.to_datetime(df_health['DATE'])\n",
        "  df_climate['DATE'] = pd.to_datetime(df_climate['DATE'])\n",
        "\n",
        "  #exposition: 5 days before extreme event\n",
        "  df_climate['exposed'] = df_climate[event].rolling(min_periods=1, window=5).sum()\n",
        "  df_climate['exposed']= np.where(df_climate['exposed']==0,0,1)\n",
        "\n",
        "  #cases \n",
        "  df_health1 = df_health.copy() #make a copy of health database\n",
        "  df_health1['case'] = 1 #all the deaths are considered cases\n",
        "  cases = pd.merge(df_health1, df_climate, on = 'DATE', how='outer') #merge with climate data\n",
        "  \n",
        "  #control - use a random number of days to determine the control\n",
        "  df_health2 = df_health.copy() #make a copy of health database\n",
        "  random_list = [] #create a random list with the size of the dataframe\n",
        "  for i in range(0,len(df_health2)):\n",
        "    random_list.append(random.randint(30, 300))\n",
        "  #use a auxiliar column to shift dates\n",
        "  df_health2['aux'] = random_list \n",
        "  df_health2['aux'] = df_health2['aux'].apply(lambda x: timedelta(days=x))\n",
        "  df_health2['DATE'] = df_health2['DATE'] - df_health2['aux'] #shift dates\n",
        "  df_health2['case']= 0 #all the shift dates are controls (a death didn't occured)\n",
        "  control = pd.merge(df_health2, df_climate, on = 'DATE', how='outer') #merge with climate data\n",
        "\n",
        "  #concat both dataframes\n",
        "  df = pd.concat([cases, control])\n",
        "  df = df[~df['case'].isnull()] #drop days without health data\n",
        "  df = df[~df['exposed'].isnull()] #drop days without climate data\n",
        "  df = df.sort_values('DATE') #sort by dates\n",
        "\n",
        "  #cases and controls, exposed and unexposed\n",
        "  case_exposed = len(df[(df['case']==1) & (df['exposed']==1)])\n",
        "  case_unexposed = len(df[(df['case']==1) & (df['exposed']==0)])\n",
        "  control_exposed = len(df[(df['case']==0) & (df['exposed']==1)])\n",
        "  control_unexposed = len(df[(df['case']==0) & (df['exposed']==0)])\n",
        "  \n",
        "  #if show=True, print\n",
        "  if show:\n",
        "    print(f\"case exposed: {case_exposed} \\ncase unexposed: {case_unexposed} \\ncontrol exposed: {control_exposed} \\ncontrol unexposed: {control_unexposed} \\n\")\n",
        "\n",
        "  #logistic regression - only with the event (exposition) as variable\n",
        "  y = df['case']\n",
        "  x = df['exposed']\n",
        "  x = sm.add_constant(x)\n",
        "  model = sm.Logit(y, x)\n",
        "  result = model.fit(method='newton',disp=False)\n",
        "  IRR = np.exp(result.params[1])\n",
        "  \n",
        "  #if show=True, print\n",
        "  if show:\n",
        "    print(\"IRR:\", round(np.exp(result.params[1]),2))\n",
        "\n",
        "  #return dataframe\n",
        "  return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoCXCRL_ScfQ"
      },
      "source": [
        "def regression(data,event,variables):\n",
        "        ###data - health data\n",
        "        ###event - extreme event we want to compute the RR\n",
        "        ###variables - explanatory variables\n",
        "\n",
        "  #get the dataframe with cases and controls\n",
        "  df = case_crossover_random_exposed(data, df_VCP,event,False)\n",
        "  #y is the result - case or control\n",
        "  y = df['case']\n",
        "  #x are all of the explanotory variables\n",
        "  x = df[variables]\n",
        "\n",
        "  #perfom a logistic regression regression\n",
        "  model = sm.Logit(y, x)\n",
        "  result = model.fit(method='newton', disp=False)\n",
        "  #rate ratio is the exponential of the coeficient associated to the extreme event\n",
        "  RR = round(np.exp(result.params[0]),2)\n",
        "  #confidence intervals\n",
        "  ci = result.conf_int()\n",
        "  lower_ci = round(np.exp(ci.iloc[0,0]),2)\n",
        "  upper_ci = round(np.exp(ci.iloc[0,1]),2)\n",
        "  \n",
        "  #return the RR and CI\n",
        "  return RR, lower_ci, upper_ci"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL2Y00EueTym"
      },
      "source": [
        "def mean_rr(number,data,event,variables):\n",
        "  ### number - times of regressions to compute the mean\n",
        "  ### data - health database\n",
        "  ###event - extreme event we want to compute the RR\n",
        "  ###variables - explanatory variables\n",
        "\n",
        "  #insert the exposition to the extreme event in the variables list\n",
        "  variables.insert(0,'exposed')\n",
        "  \n",
        "  #create lists to store results\n",
        "  irr_list = []\n",
        "  lower_ci_list = []\n",
        "  upper_ci_list = []\n",
        "\n",
        "  #perform the regression n times\n",
        "  for i in range(0, number+1):\n",
        "    irr, lower_ci, upper_ci = regression(data,event,variables)\n",
        "    irr_list.append(irr)\n",
        "    lower_ci_list.append(lower_ci)\n",
        "    upper_ci_list.append(upper_ci)\n",
        "\n",
        "  #get the mean values\n",
        "  print(\"IRR:\",irr_list)\n",
        "  print(\"IRR:\", round(stat.mean(irr_list),2))\n",
        "  print(\"lower ci:\",lower_ci_list)\n",
        "  print(\"upper ci:\",upper_ci_list)\n",
        "  print(f\"CI: {round(stat.mean(lower_ci_list),2)} - {round(stat.mean(upper_ci_list),2)}\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3BAp6yNNE6x"
      },
      "source": [
        "##**Analysis**\n",
        "\n",
        "Perform the regression 20 times and take the mean values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jx1ET994fjXf",
        "outputId": "2774bee8-5cfd-4ea0-f8b1-25b9360ae8d7"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'above_temp_range',columns)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [0.86, 0.84, 0.88, 0.88, 0.9, 0.87, 0.9, 0.88, 0.88, 0.87, 0.89, 0.86, 0.88, 0.86, 0.89, 0.91, 0.92, 0.9, 0.9, 0.86, 0.9]\n",
            "IRR: 0.88\n",
            "lower ci: [0.81, 0.8, 0.83, 0.83, 0.85, 0.82, 0.85, 0.83, 0.83, 0.82, 0.83, 0.81, 0.83, 0.81, 0.84, 0.86, 0.87, 0.85, 0.85, 0.81, 0.85]\n",
            "upper ci: [0.91, 0.9, 0.93, 0.93, 0.96, 0.93, 0.96, 0.94, 0.93, 0.93, 0.94, 0.92, 0.94, 0.91, 0.95, 0.97, 0.98, 0.96, 0.95, 0.92, 0.96]\n",
            "CI: 0.83 - 0.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pO_EWuKPJFb",
        "outputId": "2a47bdf9-d599-41cd-a2a9-496a11e2b9d0"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'above_temp_dif',columns)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [1.07, 1.02, 1.07, 1.06, 1.07, 1.09, 1.08, 1.06, 1.04, 1.1, 1.21, 1.05, 1.09, 1.07, 1.01, 1.12, 1.11, 1.07, 1.05, 1.12, 1.1]\n",
            "IRR: 1.08\n",
            "lower ci: [0.96, 0.92, 0.96, 0.95, 0.96, 0.98, 0.97, 0.95, 0.93, 0.99, 1.08, 0.95, 0.98, 0.96, 0.91, 1.0, 1.0, 0.96, 0.94, 1.0, 0.99]\n",
            "upper ci: [1.19, 1.13, 1.2, 1.18, 1.19, 1.21, 1.2, 1.18, 1.16, 1.23, 1.35, 1.17, 1.21, 1.19, 1.13, 1.25, 1.24, 1.19, 1.17, 1.24, 1.23]\n",
            "CI: 0.97 - 1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2mBtrcZPKJO",
        "outputId": "b64a498c-0c77-4eca-e956-bc8dae7c9c9a"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'LPW',columns)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [1.13, 1.12, 1.12, 1.08, 1.22, 1.08, 1.18, 1.13, 1.11, 1.12, 1.16, 1.08, 1.08, 1.13, 1.1, 1.16, 1.08, 1.07, 1.2, 1.15, 1.14]\n",
            "IRR: 1.13\n",
            "lower ci: [1.01, 1.0, 1.0, 0.97, 1.09, 0.97, 1.05, 1.01, 0.99, 1.0, 1.04, 0.97, 0.97, 1.01, 0.98, 1.04, 0.97, 0.95, 1.07, 1.03, 1.02]\n",
            "upper ci: [1.26, 1.25, 1.25, 1.21, 1.37, 1.21, 1.32, 1.27, 1.24, 1.26, 1.3, 1.21, 1.21, 1.26, 1.23, 1.3, 1.21, 1.19, 1.35, 1.29, 1.28]\n",
            "CI: 1.01 - 1.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU40lMHlPMOa",
        "outputId": "1dfe9754-ee65-4af6-d720-0e321211952d"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'HPW',columns)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [1.03, 1.05, 1.06, 1.07, 1.01, 1.07, 1.02, 1.05, 1.05, 1.06, 1.03, 1.05, 1.01, 1.05, 1.0, 1.0, 1.03, 1.08, 1.05, 1.06, 1.02]\n",
            "IRR: 1.04\n",
            "lower ci: [0.97, 0.98, 0.99, 1.0, 0.95, 1.0, 0.96, 0.98, 0.99, 1.0, 0.97, 0.98, 0.95, 0.98, 0.94, 0.94, 0.97, 1.01, 0.98, 1.0, 0.96]\n",
            "upper ci: [1.1, 1.12, 1.13, 1.14, 1.08, 1.14, 1.09, 1.12, 1.12, 1.14, 1.1, 1.12, 1.08, 1.12, 1.07, 1.07, 1.1, 1.15, 1.12, 1.14, 1.09]\n",
            "CI: 0.98 - 1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mqcSSsAPRUL",
        "outputId": "6d1bd033-6fc0-4663-a879-3612000c2609"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'above_pressure_dif',columns)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [0.97, 0.96, 0.96, 1.02, 0.97, 0.97, 0.94, 0.96, 0.98, 0.97, 0.98, 0.99, 0.97, 0.99, 0.96, 0.98, 1.0, 0.98, 0.98, 0.96, 0.99]\n",
            "IRR: 0.98\n",
            "lower ci: [0.92, 0.91, 0.91, 0.96, 0.93, 0.92, 0.89, 0.91, 0.93, 0.92, 0.93, 0.94, 0.92, 0.94, 0.92, 0.93, 0.95, 0.93, 0.93, 0.91, 0.94]\n",
            "upper ci: [1.02, 1.01, 1.01, 1.07, 1.03, 1.02, 0.99, 1.01, 1.03, 1.02, 1.04, 1.04, 1.02, 1.04, 1.02, 1.03, 1.05, 1.03, 1.03, 1.01, 1.04]\n",
            "CI: 0.93 - 1.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-yXVrn5PNEg",
        "outputId": "e840e9a0-abfa-4e18-c22c-4bb2fafaac0e"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'LHW',columns)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [1.03, 1.05, 1.03, 1.02, 1.04, 1.02, 1.02, 1.05, 1.05, 1.05, 0.97, 1.05, 1.08, 1.04, 1.02, 1.02, 1.08, 0.96, 1.06, 1.03, 1.05]\n",
            "IRR: 1.03\n",
            "lower ci: [0.95, 0.97, 0.95, 0.94, 0.96, 0.94, 0.94, 0.97, 0.96, 0.96, 0.89, 0.97, 1.0, 0.96, 0.94, 0.94, 1.0, 0.89, 0.98, 0.95, 0.97]\n",
            "upper ci: [1.12, 1.14, 1.11, 1.11, 1.13, 1.11, 1.11, 1.14, 1.13, 1.13, 1.05, 1.14, 1.17, 1.13, 1.1, 1.11, 1.17, 1.05, 1.15, 1.11, 1.14]\n",
            "CI: 0.95 - 1.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWsx2H13PN28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16bd7b1-d8a9-4560-d632-321a7fc93633"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'HHW',columns)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [0.33, 0.35, 0.33, 0.36, 0.39, 0.4, 0.34, 0.44, 0.39, 0.4, 0.36, 0.37, 0.44, 0.37, 0.37, 0.35, 0.38, 0.38, 0.36, 0.33, 0.35]\n",
            "IRR: 0.37\n",
            "lower ci: [0.25, 0.27, 0.25, 0.27, 0.29, 0.3, 0.25, 0.33, 0.29, 0.3, 0.27, 0.28, 0.33, 0.28, 0.28, 0.26, 0.28, 0.29, 0.27, 0.25, 0.26]\n",
            "upper ci: [0.44, 0.47, 0.44, 0.48, 0.52, 0.54, 0.45, 0.59, 0.52, 0.54, 0.48, 0.5, 0.59, 0.5, 0.5, 0.46, 0.5, 0.51, 0.47, 0.44, 0.46]\n",
            "CI: 0.28 - 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU34CwgwPVHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0ab0263-beb8-436b-8bcf-a7626e7b6781"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'above_humidity_range',columns)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [0.92, 0.9, 0.92, 0.94, 0.94, 0.96, 0.94, 0.93, 0.93, 0.93, 0.95, 0.92, 0.94, 0.93, 0.93, 0.93, 0.93, 0.95, 0.92, 0.91, 0.93]\n",
            "IRR: 0.93\n",
            "lower ci: [0.88, 0.86, 0.87, 0.89, 0.89, 0.91, 0.89, 0.89, 0.88, 0.88, 0.91, 0.87, 0.89, 0.89, 0.89, 0.88, 0.89, 0.91, 0.87, 0.87, 0.88]\n",
            "upper ci: [0.97, 0.95, 0.97, 0.99, 0.99, 1.01, 0.99, 0.98, 0.98, 0.98, 1.0, 0.97, 0.99, 0.98, 0.98, 0.97, 0.98, 1.01, 0.97, 0.96, 0.98]\n",
            "CI: 0.89 - 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mPrOTrRPS93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ebcbdb-8774-45c8-dd92-03e549d27503"
      },
      "source": [
        "columns = ['TMAX','AVGPRESSURE','HMAX']\n",
        "mean_rr(20,df_hosp,'above_humidity_dif',columns)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IRR: [1.01, 0.97, 1.05, 1.03, 1.07, 0.97, 1.04, 1.02, 1.1, 1.04, 1.02, 0.96, 1.08, 0.96, 1.03, 0.96, 0.98, 1.01, 1.04, 1.01, 1.05]\n",
            "IRR: 1.02\n",
            "lower ci: [0.91, 0.87, 0.94, 0.92, 0.96, 0.88, 0.94, 0.92, 0.99, 0.94, 0.92, 0.87, 0.97, 0.86, 0.93, 0.87, 0.89, 0.91, 0.94, 0.91, 0.95]\n",
            "upper ci: [1.12, 1.07, 1.16, 1.14, 1.19, 1.08, 1.16, 1.13, 1.22, 1.16, 1.13, 1.07, 1.2, 1.06, 1.14, 1.07, 1.09, 1.12, 1.16, 1.12, 1.17]\n",
            "CI: 0.92 - 1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLX-wDU0fmOV"
      },
      "source": [
        "##**References**\n",
        "\n",
        "L. Gordis, “Epidemiology, Saunders Elsevier\", Philadelphia, Pa, USA, 2013.\n",
        "\n",
        "H. T. O. Davies, I. K. Crombie, and M. Tavakoli, “When can odds ratios mislead?”Bmj, vol.316, no. 7136, pp. 989–991, 1998."
      ]
    }
  ]
}